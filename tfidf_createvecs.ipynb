{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thomouvic/txtanalytics/blob/main/tfidf_createvecs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/thomouvic/txtanalytics/raw/main/txts.zip\n",
        "!unzip -q txts.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiyTlMT0u0kv",
        "outputId": "2cf24ab9-1b85-40a1-ace8-57df363f460a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-14 00:02:50--  https://github.com/thomouvic/txtanalytics/raw/main/txts.zip\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/thomouvic/txtanalytics/main/txts.zip [following]\n",
            "--2022-11-14 00:02:50--  https://raw.githubusercontent.com/thomouvic/txtanalytics/main/txts.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3274958 (3.1M) [application/zip]\n",
            "Saving to: ‘txts.zip’\n",
            "\n",
            "txts.zip            100%[===================>]   3.12M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-11-14 00:02:50 (58.7 MB/s) - ‘txts.zip’ saved [3274958/3274958]\n",
            "\n",
            "replace txts/03_Jensen_Its-not-Personal_WJS_Vol13_No-2_Fall-2017_pp-140-166.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "all_txt_files =[]\n",
        "for file in Path(\"./txts/\").rglob(\"*.txt\"):\n",
        "  # print(file)\n",
        "  all_txt_files.append(file.parent / file.name)\n",
        "\n",
        "n_files = len(all_txt_files)\n",
        "print(n_files)"
      ],
      "metadata": {
        "id": "_Ez42xyxWPFj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62deef99-5cee-4aa4-d0f8-73fb4a8869fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "all_txt_files.sort()\n",
        "all_txt_files[0]\n",
        "\n",
        "# A: store docnames to a pandas frame, then to a csv file\n",
        "df_docnames = pd.DataFrame({'docname':all_txt_files})\n",
        "df_docnames['docid'] = df_docnames.index\n",
        "df_docnames.to_csv('docnames.csv', index=False)\n",
        "\n",
        "print(df_docnames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhvoTN2JxGOy",
        "outputId": "650a9db8-f5d1-473e-add9-34363caf49fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               docname  docid\n",
            "0    txts/03_Jensen_Its-not-Personal_WJS_Vol13_No-2...      0\n",
            "1         txts/ACH-ALL-2005-Conference-Proceedings.txt      1\n",
            "2                                    txts/Abstract.txt      2\n",
            "3    txts/Arbuckle-2020-How-Can-We-Broaden-and-Dive...      3\n",
            "4    txts/Arbuckle-Christie-Siemens_IntroductionSRC...      4\n",
            "..                                                 ...    ...\n",
            "125  txts/Winter-et-al-2020-Foundations-for-the-Can...    125\n",
            "126                        txts/eludamos7.1_jensen.txt    126\n",
            "127                                 txts/hubREADME.txt    127\n",
            "128                           txts/newDraftVersion.txt    128\n",
            "129                       txts/project_muse_787134.txt    129\n",
            "\n",
            "[130 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "all_docs = [open(f).read() for f in all_txt_files]\n",
        "vectorizer = TfidfVectorizer(max_df=.65, min_df=1, stop_words={'english'}) # A: removed norm=None\n",
        "transformed_documents = vectorizer.fit_transform(all_docs) # A: This is a sparse matrix\n",
        "\n",
        "print(transformed_documents)\n",
        "# A: In a sparse matrix, we have the rows and cols that have non-zero entries, \n",
        "# the numbers are the tfidf of the words. \n",
        "# E.g. (0, 6132)\t0.0018000350124242881 means that in doc 0, word 6132 \n",
        "# has tfidf 0.0018000350124242881\n",
        "# If you want to see what's word 6132, do vectorizer.get_feature_names()[6132]\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(vectorizer.get_feature_names_out()[6132])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C5Fei0Txsil",
        "outputId": "f91881cf-f919-4ad4-e7de-e10803e6f322"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 1845)\t0.0034066976223548744\n",
            "  (0, 1840)\t0.0034066976223548744\n",
            "  (0, 1523)\t0.0027646746887672454\n",
            "  (0, 6132)\t0.0018000350124242881\n",
            "  (0, 42161)\t0.00351579337027075\n",
            "  (0, 2786)\t0.002291525876047508\n",
            "  (0, 38523)\t0.004424279896694256\n",
            "  (0, 49538)\t0.0021226517551796165\n",
            "  (0, 45167)\t0.004799839237446008\n",
            "  (0, 45168)\t0.004799839237446008\n",
            "  (0, 12411)\t0.003951131083974518\n",
            "  (0, 1353)\t0.004799839237446008\n",
            "  (0, 22139)\t0.0020021909161804527\n",
            "  (0, 37456)\t0.003066095007628514\n",
            "  (0, 2771)\t0.002291525876047508\n",
            "  (0, 1086)\t0.0029974529947649152\n",
            "  (0, 43138)\t0.003066095007628514\n",
            "  (0, 2116)\t0.003951131083974518\n",
            "  (0, 354)\t0.002714595287184984\n",
            "  (0, 363)\t0.0021755943531760404\n",
            "  (0, 1007)\t0.0026670852167992604\n",
            "  (0, 527)\t0.002621893654013163\n",
            "  (0, 2544)\t0.0019159665352957555\n",
            "  (0, 1162)\t0.003066095007628514\n",
            "  (0, 25976)\t0.0036394759283525442\n",
            "  :\t:\n",
            "  (129, 32182)\t0.019182853946552503\n",
            "  (129, 13207)\t0.001370203853325179\n",
            "  (129, 10819)\t0.002811189108572395\n",
            "  (129, 40026)\t0.012559857008466168\n",
            "  (129, 41192)\t0.015325509456947802\n",
            "  (129, 26002)\t0.1368028732590195\n",
            "  (129, 44433)\t0.005424901424268584\n",
            "  (129, 36976)\t0.0018083004747561947\n",
            "  (129, 40602)\t0.0027996302047486395\n",
            "  (129, 37784)\t0.003244226741575352\n",
            "  (129, 15699)\t0.002554251576157967\n",
            "  (129, 22681)\t0.00943150880006479\n",
            "  (129, 40646)\t0.005976027608349128\n",
            "  (129, 49441)\t0.006029501013453684\n",
            "  (129, 32187)\t0.01616830080011107\n",
            "  (129, 28179)\t0.003223736666765833\n",
            "  (129, 17030)\t0.00688398738493808\n",
            "  (129, 20242)\t0.003991326551154742\n",
            "  (129, 29836)\t0.0467219501423715\n",
            "  (129, 24410)\t0.007794831733540923\n",
            "  (129, 44505)\t0.008398890614245917\n",
            "  (129, 29708)\t0.0036545959194772895\n",
            "  (129, 56930)\t0.00701438406639689\n",
            "  (129, 34963)\t0.008234777239775\n",
            "  (129, 39775)\t0.001534721200830432\n",
            "['00' '000' '0000' ... '新唐書' '舊唐書' '資治通鑑']\n",
            "argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A: Let's transform the sparse matrix to a pandas dataframe, then save it to a file.  \n",
        "import pandas as pd\n",
        "\n",
        "m = transformed_documents.tocoo()\n",
        "tuples = zip(m.row, m.col, m.data)\n",
        "df1 = pd.DataFrame(tuples, columns =['docid', 'termid', 'score'])\n",
        "# print(df1)\n",
        "\n",
        "df2 = pd.DataFrame(vectorizer.get_feature_names_out(), columns = ['term'])\n",
        "df2['termid'] = df2.index\n",
        "# print(df2)\n",
        "\n",
        "df3 = df1.merge(df2, on='termid')\n",
        "df3 = df3.sort_values(['docid', 'score'], ascending=[True, False])\n",
        "print(df3)\n",
        "\n",
        "print(all_txt_files[0], '\\n', df3[df3['docid'] == 0])\n",
        "df3.to_csv('docvecs.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4pii-JyyqbI",
        "outputId": "004e55e2-3963-4eb4-cb3f-84c2c12f4ae0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        docid  termid     score        term\n",
            "45731       0   41217  0.796370       pratt\n",
            "46291       0   29708  0.260721       james\n",
            "46276       0   44505  0.183921    religion\n",
            "46082       0   44509  0.178289   religious\n",
            "34894       0    9441  0.153595     brébeuf\n",
            "...       ...     ...       ...         ...\n",
            "40070     129   22449  0.001336   following\n",
            "6396      129   57642  0.001303        york\n",
            "9561      129   14323  0.001303    creation\n",
            "157199    129   18905  0.001303  electronic\n",
            "36323     129   41178  0.001293   practices\n",
            "\n",
            "[226354 rows x 4 columns]\n",
            "txts/03_Jensen_Its-not-Personal_WJS_Vol13_No-2_Fall-2017_pp-140-166.txt \n",
            "        docid  termid     score        term\n",
            "45731      0   41217  0.796370       pratt\n",
            "46291      0   29708  0.260721       james\n",
            "46276      0   44505  0.183921    religion\n",
            "46082      0   44509  0.178289   religious\n",
            "34894      0    9441  0.153595     brébeuf\n",
            "...      ...     ...       ...         ...\n",
            "34457      0   42661  0.001372  publishing\n",
            "9479       0   14323  0.001338    creation\n",
            "10089      0   47183  0.001338     science\n",
            "27260      0    3361  0.001327        able\n",
            "36240      0   41178  0.001327   practices\n",
            "\n",
            "[2062 rows x 4 columns]\n"
          ]
        }
      ]
    }
  ]
}